---
title: "Data Analysis"
output: html_notebook
---

Goal- get species richness for each camera in each forest, then get average species richness for the entire forest for those cameras with standard deviation, then average of 3 forests of each type.

Install necessary packages and import the data set. Data is output from 'join_mess-NoCoWild.Rmd' 
```{r}
rm(list = ls())
library(dplyr)
library(magrittr)
library(stringr)
library(tidyr)
library(ggplot2)
library(readr)
library(vegan)

getwd()

DF <- read_csv("TestingAnnotations/Testing/R1B1_muddy_results.csv")
```

# note that the total_species count reported here isn't accurate when users report the same species multiple times. 

```{r}
head(DF)
```

Summarize the data and create a new column that has a count of how many unique identifications, and tallies how many people identified each new photo.
```{r}
DF %>% summarise(n_distinct(subject_ids), n_distinct(classification_id)) 


New<- DF %>% 
     group_by(subject_ids) %>% # count up the number of distinct classification IDs
     mutate(., num_class = n_distinct(classification_id)) %>% #because there will be >1 row per classification_id if >1 spp
     arrange(., subject_ids, classification_id) 
DF %>% View


```


#Need to Identify behavior columns, how many columns, etc. Let's get data input out of the way now.
Not sure yet how this helps us...
```{r}
howmany_column <- "Number" # this is a special kind of single-answer column. 
multi_answer_cols <- names(select(ungroup(DF), starts_with("behavior"))) #the flattening script handily appends this to the front of behavior columns.
yesno_columns <- NULL # no single-answer columns here, other than how many, which gets special treatment.
```



# NOTE THAT YOU NEED TO PROVIDE THE MAPPING LATER ON IF YOU USE A HOW MANY COLUMN. I CAN'T SEEM TO GET THE FUNCTION TO ACCEPT VARIABLES. 
# howmany_map_from <- c("1", "2", "35", "610", "MANY")
# howmany_map_to <- c("1", "2", "4", "8", "20") # need to provide a numeric map (at least until I can write a function to get medians for ordered factors)
# lookup_list <- as.character("'1' = '1', '2' = '2', '35' = '4', '610' = '8', 'MANY' = '20'")



########### CLEAN UP MULTIPLE VOTES PER USER ###############
# number of different species should match the number of submissions per user.
# research team needs to decide how to combine duplicate entries per user. 
# Easiest thing is to just take the first submission, though most robust thing is probably to combine the answers.
# Note: this will be difficult without knowing what is a count, etc. Research teams can create their own, or, hoping it's relatively rare, just drop the extras.

 
```{r}
check_spp_counts <- New %>% 
     group_by(subject_ids, classification_id) %>% 
     mutate(., num_species = n_distinct(choice), check_num_spp = n())
```

Check for duplicates. Need to use function Zooniverse people created
```{r}
check_dups <- function(New) {
     # This function groups by subject and classification ID (which is per user/classification), 
     # then checks whether the number of unique species == the number of submissions. 
     # So, if a person selects lion & zebra, num_species and check_num_species will both = 2. 
     # If a person selects lion, 1, standing and lion, 1, sitting, then num_species = 1 and check_num_species = 2.
     # Note that this error will not be possible in future projects.
     # Also note that we can't actually combine answers in a generalized way, 
     # because "how many" is actually categorical and the values differ for all projects.
     bad_counts <- New %>% 
          group_by(subject_ids, classification_id) %>% 
          mutate(., num_species = n_distinct(choice), check_num_spp = n()) %>%
          filter(., num_species != check_num_spp) 
     check <- bad_counts %>% nrow() %>% as.numeric()
     
     if(check > 0) {
          print("You've got duplicates, dammit")
          return(bad_counts)
     } else if(check == 0) {
          print("You've got no duplicates! Well done!")
     }
}

```

```{r}
bad_counts <- check_dups(New)
```
If this is working, it appears that there are no duplicates.

# can just run this - sets cleaned_classifications to the correct dataset, dropping duplicates where necessary
```{r}
if(is.null(dim(bad_counts))) {
     print("No duplicates to drop")
     cleaned_classifications <- check_spp_counts
} else {
     # NOTE that I don't know how you combine different answers for a single choice questions, thus, this just takes the FIRST anser
     print(paste("Dropping", dim(check_dups(raw_data))[1], "duplicate classifications"))
     
     cleaned_classifications <- raw_data %>% group_by(subject_ids, classification_id) %>% 
          mutate(., num_species = n_distinct(choice)) %>%
          group_by(., subject_ids, classification_id, num_class, num_species, choice) %>% 
          #summarise_all(., sum) # adds up counts for duplicates of spp, only works if everything is numeric
          summarise_all(., first) # takes the first record per user per species classification
}



check_dups(cleaned_classifications)

```


####################### AGGREGATE! #######################

 
##### SUBJECT-LEVEL METRICS

```{r}
subject_metrics <- cleaned_classifications %>% ungroup %>%
     group_by(., subject_ids) %>%
     mutate(., num_votes = n(), # if a  user ids >1 spp, there will be more votes than classifications
            diff_species = n_distinct(choice)) # count the total number of different species reported by different users, for pielous score

glimpse(subject_metrics)
```


# Calculate aggregate number of species per subject by taking the median number of species reported across all volunteers, and tie back to subject metrics.
```{r}
species_counts <- cleaned_classifications %>% ungroup %>%
     group_by(subject_ids, classification_id) %>%
     summarise(total_spp_by_user = mean(num_species)) %>% #Need to select only one row per classification_id, then summarise across those. 
     summarise(., agg_num_species = round(median(total_spp_by_user), 0))#aggregate species count, which is median rounded up
     glimpse(species_counts)

cleaned_classifications <- left_join(subject_metrics, species_counts) %>% ungroup
glimpse(cleaned_classifications)
```



####### SPECIES-LEVEL METRICS

### For each species, aggregate counts and behavior votes. ###
# okay, so there's a difference between the proportion of VOTES and the proportion of classifications. 
# If some users ID >1 species in a single species image, there will be more votes than classifications. 
# The opposite is true for when some users only ID 1 species in a multi-species image.


#this provides one row per species ID per classification. We actually don't really need all the grouping variables... could just pull them apart and save for later.
```{r}
grouped_classifications <- cleaned_classifications %>% 
     select(., -num_species) %>% # these aren't relevant
     group_by(., subject_ids, num_class, num_votes, agg_num_species, diff_species, choice) # fields at subject level or higher
```


#Tally the votes for each species ID'd within a subject
```{r}
species_votes <- grouped_classifications %>% 
     # for every species within a subject, aggregate votes.
     summarise(., votes = n_distinct(classification_id)) %>% #count up the number of votes per species choice
     mutate(propvote = votes/sum(votes), #calculate proportion of votes for this species
            propclass = votes/num_class) #calculate proportion of classifications for this species
```


# # Tally votes for factor questions with single YES OR NO answers. STILL NEED to create a function to calculate proportions for different answer types.
# question_votes <- grouped_classifications %>% 
#      summarise_at(., .cols = yesno_columns, funs(calc_yes))

Need to use 'calc_prop' function defined by Zooniverse people
```{r}
calc_prop <- function(x, NA_action = "non_answer") {
     #NA_action can be non_answer or zero, indicating how NAs should be treated. By default, they are treated as non_answers
     # sum(x)/length(x)  
     
     if (NA_action == "non_answer") {
          prop<- sum(x[!is.na(x)])/length(x[!is.na(x)]) # Remove NAs from both sum and length
          prop <- ifelse(is.finite(prop), prop, NA)          
     } else if (NA_action == "zero") {
          prop<- sum(x, na.rm = T)/length(x) #NAs count towards total length, but not towards the sum of 1s.
     }
     
}
```


# Tally votes for the different behaviors (or other multi-choice feature) for each species.
```{r}
multi_answer_votes <- grouped_classifications %>%
     summarise_at(., .vars = multi_answer_cols, funs(calc_prop))

howmany_votes <- grouped_classifications %>%
     mutate(Number = dplyr::recode(as.character(Number), '1' = '1', '2' = '2', '35' = '4', '610' = '8', 'MANY' = '20')) %>%
     mutate(Number = as.numeric(Number)) %>%
     summarise_at(., .vars = howmany_column, funs(med_count = median, min_count = min, max_count = max))
```


# Okay, so the full dataset has all of the aggregate votes per species. The only thing left is to select the top n species for each subject.
```{r}
all_data <- full_join(species_votes, howmany_votes) %>% full_join(., multi_answer_votes)

write.csv(all_data, file = "cleaned_data.csv")
```

```{r}
Bad_data <- filter(all_data, diff_species > 1)

Bad_data_final <- Bad_data %>% group_by(subject_ids, votes) %>%   
     

Final_data <- all_data %>% group_by(subject_ids)
```

```{r}
Good_data <- all_data %>% group_by(subject_ids) %>% summarise(
     votes = length(votes)
)
X <- filter(Good_data, num_rows > 1) 

```

```{r}
Group<- all_data %>% group_by(all_data$subject_ids) %>% order_by(all_data$votes)
```

Import modified data frame
```{r}
Final_data <- read_csv("~/Dropbox/Zooniverse_work/Final_data.csv")
```

Match the forest type with subject ID
```{r}
Sifted_data<- DF[match(unique(DF$subject_ids), DF$subject_ids),]

write.csv(Sifted_data, file = "Sifted_data.csv")
```

```{r}
duplicated(Final_data$subject_ids)
length(Final_data$subject_ids)


```

The final data frame did not contain dates. We need to add these in. 
```{r}
Metadata <- read.csv("~/Dropbox/Zooniverse_work/Game Camera Metadata Field Sheets 2019.csv")

Metadata1<- select(Metadata, Date.Out, Date.Checked, SD.Card.Number, Unit.Number) 

names(Metadata1)<- c("Date_Out", "Date_Checked", "SDCard", "Camera")

write.csv(Metadata1, "Metadata.csv")
```

Import final dataset to add dates column. We need to add date in the field and date retrieved in order to calculate species accumulation curve. 
```{r}
Data_Clean_up <- read.csv("~/Dropbox/Statistical_Analysis/Data_Clean_up.csv")

#Be sure the merging columns have the same names and are both characters

Data_Clean_up$Camera<- as.character(Data_Clean_up$Camera)
Data_Clean_up$SDCard<- as.character(Data_Clean_up$SDCard)

joinedData <- left_join(Data_Clean_up, Metadata1, by=c("SDCard", "Camera"), type='right', match='all')

write.csv(joinedData, file = "joinedData.csv")
```

This seemed to match the correct deployment and collection date for each subject_id. Now we can do a species accumulation curve. 

#Species Accumulation Curve
```{r}
joinedData <- read.csv("~/Dropbox/Zooniverse_work/joinedData.csv")
library(vegan)


#Reformulate deployment dates so they are as.dates and they are in the same order for taking the difference later on
joinedData$Date_Checked<- format(as.Date(joinedData$Date_Checked, format="%m/%d/%y"),"%y/%m/%d")

joinedData$Date_Out<- format(as.Date(joinedData$Date_Out, format="%m/%d/%y"),"%y/%m/%d")

#Calculate Camera Trap Days by taking the difference in Date_Out and Date_Checked data. 
joinedData$Camera_Trap_Days<- difftime(joinedData$Date_Checked, joinedData$Date_Out , units = c("days"))


#Need to determine how many new species introduced with each additional camera trap day
#Calculate species richness for each camera
Camera_richness <- DF %>% group_by(ForestType, ForestName, Camera) %>% summarise(
  Number_species = n_distinct(choice)
  )

#We only have 20 of our 24 cameras being represented in our dataset
unique(Camera_richness$Camera)

#pull in camera trap days per camera and first image in event
Cam_Trap_Days<- select(joinedData, ForestName, Camera, Camera_Trap_Days, Image1)

Camera_richness1 <- left_join(Camera_richness, Cam_Trap_Days, by=c("ForestName", "Camera"), type='right', match='all')

#This gives an output that has 931 observation of 5 variables. This has duplicates that we need to remove to get a dataset that has each camera with associated forest and number of camera trap days. 
Camera_richness2<- Camera_richness1[!duplicated(Camera_richness1$Camera, Camera_richness1$ForestName),]

#Camera_richness2 has one row for each camera with the forest name, species richness, and camera trap days
#Now calculate species accumulation curve
library(vegan)
Camera_richness2 <-Camera_richness1[,1:5]=sapply(Camera_richness1[,1:5],as.numeric)
#SpecAccum<- specaccum(Camera_richness2)

#Problem here. Is it possible to calculate species accumulation curve wihen we cannot tell how many new species added each day?
#Trial- add in event (subjectid data) and event date and calculate how many new species each day

R1B1 <- read.csv("~/Dropbox/Zooniverse_work/UseThisCode/R1B1.csv")

ImageDates<- select(R1B1, "FileName", "DateTimeOriginal")

names(ImageDates)<- c("Image1", "Image_Date")

ImageDates1<- select(Sifted_data, "Image1")

ImageDates2<- left_join(ImageDates, ImageDates1, by=c("Image1"), type='right', match='all')



ImageDates1<- inner_join(ImageDates, Cam_Trap_Days, by=c("Image1"), type='right', match='all')
getwd()

write.csv(ImageDates1, "/Users/Donovan/Dropbox/Zooniverse_work/Camera_Trapping_Ch5_Work.csv")

#ImageDates1 shows the first image per event with associated time of capture. This will hopefully allow us to determine how many new species we got per day. Still need to pull in choice per subject.

#Isolate choices per event to join with the ImageDates1 dataset so we can see which species are selected per event
Choice<- select(Data_Clean_up, "choice", "Image1")

Data<- inner_join(ImageDates1, joinedData, by=c("Image1"), type='right', match='all')

write.csv(Data, "/Users/Donovan/Dropbox/Zooniverse_work/Camera_Trapping_Ch5_Work/Data.csv")

library(lubridate)

Data$Date_Out <- as.Date(Data$Date_Out)
Data$Date_Checked <- as.Date(Data$Date_Checked)
     
#Calculate Species Accumulation Curve
library(vegan)
SpecAccum<- specaccum(Data, method = "exact", permutations = 100)
plot(SpecAccum)
```


#Diversity
```{r}
div<-diversity(joinedData, index="shannon")
```



